{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d637d053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ TP TRM-VISION ‚Äì Fashion-MNIST Kaggle (TRM small + classifier)\n",
      "Path to dataset files: C:\\Users\\User\\.cache\\kagglehub\\datasets\\zalando-research\\fashionmnist\\versions\\4\n",
      "‚úÖ Fashion-MNIST Kaggle: x_train=(60000, 16, 16), y_train=(60000,)\n",
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "\n",
      "üîß Entra√Ænement TRM small (Fashion-MNIST, 20 √©poques)...\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\layer_normalization.py:328: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 1706, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 28 and 16 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](mean_squared_error/remove_squeezable_dimensions/Squeeze, IteratorGetNext:1)' with input shapes: [?,28,28], [?,16,16].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 132\u001b[39m\n\u001b[32m    129\u001b[39m trm_small.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=\u001b[33m'\u001b[39m\u001b[33mmse\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    131\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müîß Entra√Ænement TRM small (Fashion-MNIST, 20 √©poques)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m hist_small = \u001b[43mtrm_small\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_small\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val_small\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# 5. CNN classifier Fashion-MNIST 28x28\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müîß Entra√Ænement CNN classifier Fashion-MNIST (28x28)...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\__autograph_generated_file0yic97o5.py:15\u001b[39m, in \u001b[36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     14\u001b[39m     do_return = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(\u001b[38;5;28mself\u001b[39m), ag__.ld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     17\u001b[39m     do_return = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: in user code:\n\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 1706, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 28 and 16 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](mean_squared_error/remove_squeezable_dimensions/Squeeze, IteratorGetNext:1)' with input shapes: [?,28,28], [?,16,16].\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "\n",
    "print(\"üöÄ TP TRM-VISION ‚Äì Fashion-MNIST Kaggle (TRM small + classifier)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Download Kaggle Fashion-MNIST\n",
    "# =============================================================================\n",
    "path = kagglehub.dataset_download(\"zalando-research/fashionmnist\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "train_csv = os.path.join(path, \"fashion-mnist_train.csv\")\n",
    "test_csv  = os.path.join(path, \"fashion-mnist_test.csv\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. TinyBlock\n",
    "# =============================================================================\n",
    "class TinyBlock(layers.Layer):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.ln = layers.LayerNormalization()\n",
    "        self.fc1 = layers.Dense(4 * d, activation=\"gelu\")\n",
    "        self.fc2 = layers.Dense(d)\n",
    "\n",
    "    def call(self, u):\n",
    "        h = self.ln(u)\n",
    "        h = self.fc1(h)\n",
    "        h = self.fc2(h)\n",
    "        return u + h\n",
    "\n",
    "# =============================================================================\n",
    "# 2. TRM-VISION small\n",
    "# =============================================================================\n",
    "class TRM_VISION(keras.Model):\n",
    "    def __init__(self, img_size=28, d=32, n_rec=2, name_suffix=\"small\"):\n",
    "        super().__init__(name=f\"TRM_VISION_{name_suffix}\")\n",
    "        self.img_size = img_size\n",
    "        self.d = d\n",
    "        self.n_rec = n_rec\n",
    "        \n",
    "        self.cond_emb = layers.Embedding(10, d)\n",
    "        self.y0 = self.add_weight(\n",
    "            shape=(1, img_size*img_size, d),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "            name=f\"y0_{name_suffix}\"\n",
    "        )\n",
    "        self.z0 = self.add_weight(\n",
    "            shape=(1, img_size*img_size, d),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "            name=f\"z0_{name_suffix}\"\n",
    "        )\n",
    "        self.block1 = TinyBlock(d)\n",
    "        self.block2 = TinyBlock(d)\n",
    "        self.to_pixels = layers.Dense(1)\n",
    "\n",
    "    def call(self, class_tokens, target_img=None, return_intermediate=False):\n",
    "        B = tf.shape(class_tokens)[0]\n",
    "        L = self.img_size * self.img_size\n",
    "        \n",
    "        c = self.cond_emb(class_tokens)              \n",
    "        c = tf.tile(tf.expand_dims(c, 1), [1, L, 1]) \n",
    "        \n",
    "        y = tf.tile(self.y0, [B, 1, 1])\n",
    "        z = tf.tile(self.z0, [B, 1, 1])\n",
    "        \n",
    "        inter_imgs = []\n",
    "\n",
    "        for _ in range(self.n_rec):\n",
    "            z = self.block2(self.block1(c + y + z))\n",
    "            y = self.block2(self.block1(y + z))\n",
    "\n",
    "        pixels = self.to_pixels(y)\n",
    "        img = tf.tanh(tf.reshape(pixels, [B, self.img_size, self.img_size, 1]))\n",
    "        if return_intermediate:\n",
    "            inter_imgs.append(img)\n",
    "\n",
    "        loss = None\n",
    "        if target_img is not None:\n",
    "            loss = tf.reduce_mean(tf.keras.losses.mse(target_img, img))\n",
    "\n",
    "        if return_intermediate:\n",
    "            return img, loss, inter_imgs\n",
    "        if loss is None:\n",
    "            return img\n",
    "        return img, loss\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Dataset Kaggle Fashion-MNIST ‚Üí 28x28\n",
    "# =============================================================================\n",
    "def load_fashion_mnist_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    labels = df['label'].values.astype(np.int64)\n",
    "    pixels = df.drop(columns=['label']).values.astype(np.float32)\n",
    "    images = pixels.reshape(-1, 28, 28)\n",
    "    return images, labels\n",
    "\n",
    "x_train_full, y_train = load_fashion_mnist_csv(train_csv)\n",
    "x_test_full,  y_test  = load_fashion_mnist_csv(test_csv)\n",
    "\n",
    "x_train_full = x_train_full / 127.5 - 1.0\n",
    "x_test_full  = x_test_full  / 127.5 - 1.0\n",
    "\n",
    "x_train = np.squeeze(tf.image.resize(tf.expand_dims(x_train_full, -1), [16, 16]).numpy())\n",
    "x_test  = np.squeeze(tf.image.resize(tf.expand_dims(x_test_full,  -1), [16, 16]).numpy())\n",
    "\n",
    "print(f\"‚úÖ Fashion-MNIST Kaggle: x_train={x_train.shape}, y_train={y_train.shape}\")\n",
    "\n",
    "# Sous-√©chantillonnage raisonnable\n",
    "train_idx = 8000\n",
    "val_idx   = 2000\n",
    "\n",
    "x_train_small = x_train[:train_idx]\n",
    "y_train_small = y_train[:train_idx]\n",
    "x_val_small   = x_test[:val_idx]\n",
    "y_val_small   = y_test[:val_idx]\n",
    "\n",
    "# =============================================================================\n",
    "# 4. TRM small \n",
    "# =============================================================================\n",
    "trm_small = TRM_VISION(img_size=28, d=32, n_rec=2, name_suffix=\"small\")\n",
    "trm_small.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "print(\"\\nüîß Entra√Ænement TRM small (Fashion-MNIST, 20 √©poques)...\")\n",
    "hist_small = trm_small.fit(\n",
    "    y_train_small, x_train_small,\n",
    "    epochs=20, batch_size=256, verbose=1,\n",
    "    validation_data=(y_val_small, x_val_small)\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. CNN classifier Fashion-MNIST 28x28\n",
    "# =============================================================================\n",
    "print(\"\\nüîß Entra√Ænement CNN classifier Fashion-MNIST (28x28)...\")\n",
    "\n",
    "cnn = keras.Sequential([\n",
    "    layers.Input(shape=(16, 16, 1)),\n",
    "    layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer=\"adam\",\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "\n",
    "cnn.fit(\n",
    "    x_train_small[..., np.newaxis], y_train_small,\n",
    "    epochs=20, batch_size=256, verbose=1,\n",
    "    validation_data=(x_val_small[..., np.newaxis], y_val_small)\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 6. √âvaluation: taux de reconnaissance des images g√©n√©r√©es\n",
    "# =============================================================================\n",
    "def eval_trm_with_cnn(trm_model, name, n_samples=500):\n",
    "    labels = np.random.randint(0, 10, size=(n_samples,))\n",
    "    gen_imgs = trm_model(tf.constant(labels)).numpy()\n",
    "    preds = cnn.predict(gen_imgs, verbose=0)\n",
    "    pred_labels = preds.argmax(axis=1)\n",
    "    acc = (pred_labels == labels).mean()\n",
    "    print(f\"üìä Taux de reconnaissance CNN sur images Fashion-MNIST g√©n√©r√©es ({name}): {acc*100:.2f}%\")\n",
    "    return acc, gen_imgs, labels\n",
    "\n",
    "acc_small, gen_small_imgs, gen_small_labels = eval_trm_with_cnn(trm_small, \"TRM small\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Grille de g√©n√©ration 0-9 \n",
    "# =============================================================================\n",
    "class_names = [\n",
    "    \"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\n",
    "    \"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"\n",
    "]\n",
    "\n",
    "def plot_grid(trm_model, title):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    for i in range(10):\n",
    "        gen_imgs = trm_model(tf.constant([i]))\n",
    "        axes[i//5, i%5].imshow(gen_imgs[0, :, :, 0], cmap='gray', vmin=-1, vmax=1)\n",
    "        axes[i//5, i%5].set_title(f\"{i}: {class_names[i]}\")\n",
    "        axes[i//5, i%5].axis('off')\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_grid(trm_small, \"TRM-VISION SMALL: G√©n√©ration Fashion-MNIST 0-9\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. Target vs g√©n√©r√© pour une classe \n",
    "# =============================================================================\n",
    "def plot_target_vs_gen(model, x_test_arr, y_test_arr, digit=5, title_prefix=\"TRM\"):\n",
    "    idx = np.where(y_test_arr == digit)[0][:4]\n",
    "    target = x_test_arr[idx]\n",
    "    gen = model(tf.constant([digit]*4)).numpy()\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    for i in range(4):\n",
    "        axes[0,i].imshow(target[i], cmap='gray', vmin=-1, vmax=1)\n",
    "        axes[0,i].set_title(f\"Vrai {digit}: {class_names[digit]}\")\n",
    "        axes[0,i].axis('off')\n",
    "        axes[1,i].imshow(gen[i, :, :, 0], cmap='gray', vmin=-1, vmax=1)\n",
    "        axes[1,i].set_title(f\"{title_prefix} G√©n√©r√©\")\n",
    "        axes[1,i].axis('off')\n",
    "    plt.suptitle(f\"Classe {digit} ({class_names[digit]}): R√©el vs {title_prefix}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_target_vs_gen(trm_small, x_test, y_test, digit=5, title_prefix=\"TRM small\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. Visualisation trajectoire interne (TRM small, une classe)\n",
    "# =============================================================================\n",
    "digit_demo = 3  \n",
    "_, _, inter_imgs = trm_small(tf.constant([digit_demo]), return_intermediate=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(inter_imgs), figsize=(4*len(inter_imgs), 4))\n",
    "if len(inter_imgs) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, img_t in enumerate(inter_imgs):\n",
    "    axes[i].imshow(img_t[0, :, :, 0].numpy(), cmap='gray', vmin=-1, vmax=1)\n",
    "    axes[i].set_title(f\"Step {i+1}\")\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle(f\"√âvolution interne TRM small ‚Äì classe {digit_demo} ({class_names[digit_demo]})\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 10. R√©capitulatif console\n",
    "# =============================================================================\n",
    "val_acc_cnn = cnn.evaluate(x_val_small[...,np.newaxis], y_val_small, verbose=0)[1]*100\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ R√©sum√© TP TRM-VISION ‚Äì Fashion-MNIST Kaggle (TRM small)\")\n",
    "print(f\"   ‚Üí TRM small: d=32, n_rec=2, loss fin:  {hist_small.history['loss'][-1]:.4f}\")\n",
    "print(f\"   ‚Üí CNN val accuracy: {val_acc_cnn:.2f}%\")\n",
    "print(f\"   ‚Üí Reconnaissance CNN sur images Fashion-MNIST TRM small: {acc_small*100:.2f}%\")\n",
    "print(\"   ‚Üí Figures: grille 0-9 (v√™tements), vrai vs g√©n√©r√©, trajectoire interne\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d31fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 11. D√©mo utilisateur : pr√©dire la classe d'une image de v√™tement\n",
    "# =============================================================================\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_user_image(img_path):\n",
    "    \"\"\"\n",
    "    Charge une image utilisateur, la convertit en 28x28 niveaux de gris\n",
    "    et la normalise dans [-1, 1] comme Fashion-MNIST.\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert(\"L\")  # Niveaux de gris\n",
    "    img = img.resize((16, 16))              # M√™me taille que le mod√®le\n",
    "    img_np = np.array(img).astype(np.float32)\n",
    "    img_np = img_np / 127.5 - 1.0           # Normalisation [-1,1]\n",
    "    return img_np\n",
    "\n",
    "def predict_user_image(img_path):\n",
    "    img_np = preprocess_user_image(img_path)\n",
    "    x = img_np[np.newaxis, ..., np.newaxis]  # [1,16,16,1]\n",
    "    preds = cnn.predict(x, verbose=0)\n",
    "    pred_class = int(np.argmax(preds[0]))\n",
    "    prob = float(np.max(preds[0]))\n",
    "    \n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(img_np, cmap=\"gray\", vmin=-1, vmax=1)\n",
    "    plt.title(f\"Pr√©diction: {pred_class} ‚Äì {class_names[pred_class]} ({prob*100:.1f} %)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    return pred_class, prob\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "# 1) mets une image dans ton dossier, par ex. \"mon_tshirt.png\" ou \"shoe.jpg\"\n",
    "# 2) appelle:\n",
    "# pred_class, prob = predict_user_image(\"mon_image_vetement.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fdbe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS8AAAERCAYAAAAqriEFAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAFpNJREFUeJzt3QdwFdXfxvFzQxBQoqJgb9hFAXvFghUVu4IKKNgrqCAyjuVv7xUboGIZ7A1RrIDYG7axKyqioCCKEBACyb7znHk3s7m5ueXckOSn389MBnKzu2ez5dlzzp7dpKIoihwAGFPS2CsAACEILwAmEV4ATCK8AJhEeAEwifACYBLhBcAkwguASY0eXq+//rq79NJL3d9//93YqwLAkEYNrylTpriDDz7YlZWVueWWWy6vedZZZx3Xt2/f6u9fe+01l0ql/L/1Rcv73//+V2/LQ00//fST38bXX399zk2j/aBp/+1OO+00t9dee7n/mrvuusuttdZabuHChUs2vO677z5/IMVfLVu2dBtuuKE744wz3O+//15QwYsWLXI9e/b0QXT22We7hjZ27FhTAfXVV1+5bt26udatW7sVVljB9enTx82cOXOJlJXcx9m+6vOCUR/mz5/v92m29frrr79caWmpe+yxx/z3V155pXvmmWdcY/rxxx/d3Xff7c4///w6z7X0r1GjRlVP+9RTT/lzad1113VLL72022ijjdzAgQPd7Nmz816H2267zW2yySauRYsWbvXVV3fnnHOOmzdvXs759HThJZdc4udZaaWV3FlnneUqKipqTFNeXu5//tBDD9WaX+e/ph82bFje65osPG8jR47Uc5DRpZdeGj344IPRiBEjomOPPTYqKSmJ2rdvH82bNy/vZX388cfRTTfdFFVVVRWyCtHaa6/ty4xVVlZG//zzj/+3EKeffrr/XTLR8hYtWhQ1FVOnTo3atm0brbfeetEtt9wSXXHFFVGbNm2izp07RwsXLqz38rRvk1977bWX31bpn//2229By//xxx/98q677rqc02o/aH/kY+bMmX65F198cZ3TPPzww1FpaWn0119/+e+XWWaZGsdTYxgwYEC04YYb1vhs8uTJtba3vrbccsuoWbNm0fTp06unXXHFFaOOHTtGF154oT8n+/fvHy211FLRxhtvHM2fPz9n+YMHD/bb7fDDD4/uvPPO6Mwzz/TbaO+99845r9ZJZansq6++OiorK4uuvPLKGtMMGTIk2nHHHbOWr/O60CwICq8PPvigxufnnHOO//yhhx6qc97y8vKoPqSHV6hs4dXUnHrqqVGrVq2iKVOmVH/2yiuv+PUfNmzYEi+/vrdVIeGVj/gClk949enTJ9p1112rv2/s8KqoqPAXpgsuuCDntAoihYMuJkkTJkyI0t1///1+WyjMspk2bZoPKm2XpKFDh/r5n3322azz9+zZM+rXr1/199r222+/ffX333//vT920zMj6cMPP/RljRs3LipEvfR57b777tXV37gqqObN5MmT3X777ef7tHr16uV/VlVV5W6++Wa36aab+mbnyiuv7E4++WRfnU+rEbrLL7/crbHGGr4q3LVrV/fFF1/UKruuPq/33nvPl92mTRu3zDLLuE6dOrlbbrmlev1uv/12//9kVTxbn9fHH3/s9t13X7fsssv6322PPfZw7777bo1p4qr+W2+95avd7dq182UfcsghtZp4ukHx9ddf53Wj4sknn3Tdu3f3fQOxPffc0zfZ4+ZPU/Lhhx+6ffbZx7Vt29a1atXKtW/f3h133HEZpx0+fLhbb731fHNlm222cR988EHOPi99r64KNZ10HGle9Z1oe4uaMfE+Te5HHXsvvvii23///auXo6bR/fffXz19sj+1kH2uG086jldccUU//THHHFPrmM7kzTffdH/88Yffn7mMGTPGzZ07t/pciu22224unY65uLshm3feecctXrzYHXnkkTU+j79/5JFHss7/zz//+HMspi4NNd9jar5qWVtvvXWdy9hqq638fKNHj3aFKHX1QCEl2nExbRAdwF26dPEdswog0Q7WDu/Xr5/r37+/Dzy1t3Wg6KRv3ry5n+6iiy7y4aUA0tdHH33k9t5771rt6UxeeeUVf7KvuuqqbsCAAW6VVVbxO/G5557z32sdpk2b5qd78MEHcy5Pobnzzjv7g3Lw4MF+HdVG10EzceJEt91229WY/swzz/Q79OKLL/ad0wprnWyPPvpo9TRPP/203wYjR46sccKk+/XXX92MGTMy7vxtt93W9901JVpX7ScFyZAhQ9zyyy/vt4H6ZdKpD0Qno/aHAuDaa691hx56qPvhhx+qj4O6jB8/3ge3tqtCsnPnzu7OO+90p556qj9xtRzRRSumYNRFRMeTaN+fcMIJfjuedNJJ/jMFacg+13rod1VYfvPNN35ddEMqvrjW5e233/Y/32KLLXJuW4W1Lgbx75bNb7/95v/Vtskm7ijXcpPi83XSpElZ59cF54477nBHHHGEv1BrG+24447+Zzq/tJ++/fZbl8uWW27pz/+ChDQbX331VV9FV1/MI4884tvcqhr+8ssvfjpVwzWd2rpJb7zxhv981KhRNT5/8cUXa3w+Y8YM347ef//9a7SDzz//fD9dspqvKrM+i6vOixcv9v1val7G/Rqx5LKyNYXSmx4HH3ywXx/1QySr26rC77LLLrW2z5577lmjrLPPPtv3U8yePbvWtPo3G1W3Nd0DDzxQ62fnnnuu/9mCBQuiptJsfPrppzN2LWRqNuq4+fPPP6s/Hz16tP98zJgx1Z9pP6SXre/Vz/rFF1/U+DxXs1H9MjoukupqNha6z7faaivfBIxde+21/nP9Ttn07t3bb4dcZs2a5denR48eUT6OP/54f8x9++23WaebNGmSX8/LLrss4znZunXrrPPPmTMn6tKli59WX5tuuqnPAfVVdujQwfeD5eOkk07yGbLEm42q4urKuuaaa/oqoarUqknojkKSroJJjz/+uB8SoVvCqirHX6o2ahkTJkzw07366qu+hqUaTPKqpTsZuagGp9qcptWVMCnklntlZaV7+eWX/ZAO3c2JqVZ39NFH+2r/nDlzasyjq3iyLF3BtRxdiWOqbek8zFbriqvloqZROjW7k9M0BfE2Vy1Xd5Sz0R2yZJND20lU88pl1113dR06dCho3VRLjZuMS2KfJ2uLOvZ1VzNXzXjWrFk1tkFdnnjiCX9OpDcZM1GN9p577vFNtg022MDlqvGoFnnNNdf4VoBqyS+88IKvDev3yXVsqUtINVHVVD/55BP/pRxQbUy1Oo0k+PLLL323jz7v3bt3rW0n2gYqK9nkzCUovNRfpCqhwkYrpoNNTcQk7Tj1VyV99913vo9Ht1QVfskv3U5Vk0Pikzx9w2u6XDs6bsJuttlmrj6omaENqtvP6XRrWf0oU6dOrfF5sm9K4nXOpw8kXVydzzQOZsGCBTWmqWv91YRI/yp2mIX2V6blKVQOO+ww3++kJstBBx3kT4pM61/MdlI/WiG0jup6yCe8QvZ5+rGqi7HCTmGQSz4vM1aTUf1C6oPL5o033nDHH3+8Px+vuOIKlw/1qarZrX5JbdcDDjjA9ejRwzdl9XvkUlJS4i8kWobOe1VI1HxWd5Eu4urC6dixo+/T+vnnn32lpK5tUEgFI6jPS30E2Trg4pqCfqkk7XQFV3KMSlLc4Wpds2bNMn4e8sZtnQAyffr0Wj/TZzqgM9XKkn0SyRpfbO21187rxKqLDkwFVPrydPCplqCObXUwv/TSS/6kuOGGG/xnyZOhmO2ULbAzUW1CNVXVAJoS9RPnCmud8Aql9Npduk8//dQdeOCB/sKtfaAgyYdqRKpNqnKhkFcQq594tdVW8zeFCnXhhRf6Gp1qrlpvHafqz9T21zGj8Yq6oCXzQdtA/WyF7Nd66bDPlzpD1STcaaedsq6kTgTRxkxW23VFzLWj4w7Xzz//POsdnHwTXoGqjapO2HS6W6gdoObzkqIDS+ugO3jp3n//fbf55ptnnV8XikxV/0JP/nS6m6abMXUtb/vtt/dfuvqrGaPmju5cqYN8Scm2T59//nkfXOnrmWmekH2uYzUZjKqZ6qSNbw7UZeONN/b7SC2Sup4yefjhh32gZ2syTp482YeCKgdqquZTY0qn0IprkGpRaf1zdWtkCtB77723uqNfN8ZUo467OBSIav7qXNZIg5i6elSrbbKPB6kqqv6Eyy67rNbPdHcyHhGs0NEVZujQoTWuwrprl4sSX1VfTZs+wji5LN0ZkVyjkFU70N0zVXmTNRU9UaCTUiew7kgVqpChEmqGqQ8p2VQZN26cv4ujuzzZ6EKh7Zn+pc+LoYtKpuXp4pJec4oDNuQRkELEd8jS96n63tTNkanJqOMgffqQfa4hH8k+Pt1t1DGdq5m3ww47+O2V7a6eylQTO3mxSFJtSeurUFVNN1sLRiEXd63URS0k3WHV9jzllFNcIXQ3XxeouNtGAaWg+vPPP/33uuuvGmH6XVA16eO7lE2y5qX+EHUEXnXVVb5jTxtcIaWrljrzNQ7r8MMP9xt/0KBBfjq1l3X1Uke8qv65bv1qB+rAUbtdJ42GI6jppaBQp6J2rugmgWi4hvoHdMCmj3WJaciGDn4dPHoGTRtft4R1Mqo6HCLfoRKix0a0fXRl18Ghq/p1113n+xG0jKZEY6bUWavhCqoFayjEiBEj/MmeqxZSLNWq1PeiISlq7qhJrZNIJ486iTOFl44DtQZuvPFGXyvQhU8d2IXuc9UmNA5MF2jV2LQNNK+acdloGjUdtQ7xeMkktSA+++wzP+ykrpplt27dfL+zAkfNP33FFB7JZya1jpIMZR1T6j/V+aIAVliqVq99md4vmY2OUa2r+tCS4ax10EVWQzzU3aB/k10GCm6Fm/pHC1IfI+zT6dazbkHXZfjw4f7Wsm6N6tazHm3QIwK6FZ0cNX3JJZdEq666qp9ut912iz7//PNaI+zTh0rE3nzzTT8SWcvXunTq1MmPGo5pSIUeg2jXrl2USqVq3I7PdLv9o48+ivbZZx9/63jppZeOunbtGr399tt5bZ9M65jvUImYfnc9rqGyl19++ahXr17Bj+csyaES2k5HHXVUtNZaa0UtWrSIVlpppah79+5+FHU+I+zTt31dQyW0Tplon+jY0rCCeFmDBg3yt+0z+frrr/3QBx1j6cNwCtnnEydO9Lf79diWptf+0fCGfOhxnvXXXz/jzzTcSMv/7LPP6pzf/f8whUxfyacJROdP+nAR/Q561Eznic6XPfbYIxo/fnxUCI3+13JvvfXWWj/T+aDHmrTsAw44wA+FSjrvvPP88bJEHw8CLNpkk038mLglId8LejYaS9a8eXM/fvK/ZsGCBdEqq6wS3XzzzQXP2+jv8wKWJDXnNJ6sqTWv0/sPNbzh6quvdv81I0eO9F1HhfatSUoJtkTWCvgPiB9106NHuYYPoX5R8wJgEjUvACZR8wJgEuEFwCTCC4BJDTrCPh//hb8UIxr9HSLTKOx86VnDEHq4NkQ+L46sS6a3g+Yj15tDswn9QxyF/KELy6ImNjCBmhcAkwgvACYRXgBMIrwAmER4ATCJ8AJgEuEFwCTCC4BJhBcAkwgvACYRXgBMIrwAmER4ATCpyb1J1dJbJQYOHBg8r/50ewj9bcFQyT+KWohZs2YFzVdWVuaK/QOyDXn8fP/990Hz6W80htLftLQialpRQc0LgE00GwGYRHgBMInwAmAS4QXAJMILgEmEFwCTCC8AJhFeAEwivACYRHgBMInwAmAS4QXAJMILgEm8Esc5d8oppwRtvNtvvz14w8+fP9/Ma0mqqqrMvN4odF2lpCTsWl5ZWRlc5oknnhg035NPPukaGq/EAYB6QLMRgEmEFwCTCC8AJhFeAEwivACYRHgBMInwAmAS4QXAJMILgEmEFwCTCC8AJhFeAEz617xVolu3bsFlhj6hX1FREVxm6JsIllpqqeAyQ3d16Hyhb2kopsxi3vAQWmZ5eXmDv12ke/fuwWVOnjw5aL4mFhXUvADYRLMRgEmEFwCTCC8AJhFeAEwivACYRHgBMInwAmAS4QXAJMILgEmEFwCTCC8AJhFeAEwivACY1OReidO1a9eg+UaNGhVcZtu2bYPmmzNnTnCZoa+LKS0tdQ2tqqrKzCtxQte1mNfp/P3338FltmnTJmi+sWPHBpfZt2/foPkWL17smhJqXgBMIrwAmER4ATCJ8AJgEuEFwCTCC4BJhBcAkwgvACYRXgBMIrwAmER4ATCJ8AJgEuEFwKSGf0VBDu3btw+ab9lllw0us6KiwllRzFsTUqlUg5YZWl4xZRazfRqjzIULFwbNd+CBBwaX2a9fP/dvQM0LgEmEFwCTCC8AJhFeAEwivACYRHgBMInwAmAS4QXAJMILgEmEFwCTCC8AJhFeAEwivACYRHgBMKnJvRJn5MiRDf5KnKuuuipovvLy8uAyQ9e3mNevlJaWmnklThRFDTpfsfOGat26ddB8kyZNCi7zyy+/dP8G1LwAmER4ATCJ8AJgEuEFwCTCC4BJhBcAkwgvACYRXgBMIrwAmER4ATCJ8AJgEuEFwCTCC4BJTe6tEqGGDh0aPO+8efOC5lu8eHFwmTfddFODv1Ui9K0JFRUVQfO1bNnSWXrDw4IFC4LmGzFiRHCZHTt2DJpv4MCBwWXOnDnT/RtQ8wJgEuEFwCTCC4BJhBcAkwgvACYRXgBMIrwAmER4ATCJ8AJgEuEFwCTCC4BJhBcAkwgvACalosZ4fD+LVCrlrOjSpUvwvGPHjg2ab+HChcFllpaGvURk7ty5QfO1atXKhWqMwzJ02+68887BZf7000/OiqhpRQU1LwA20WwEYBLhBcAkwguASYQXAJMILwAmEV4ATCK8AJhEeAEwifACYBLhBcAkwguASYQXAJMILwAmhb0jBV5ZWVmDb4mqqqrgeSsrKxu0zMZ4hUro7yglJWHX8hYtWgSXiXDUvACYRHgBMInwAmAS4QXAJMILgEmEFwCTCC8AJhFeAEwivACYRHgBMInwAmAS4QXAJMILgEm8VaIIjfHWhGLKbOj1Laa8VCrV4G/dCC2Tt0o0DmpeAEwivACYRHgBMInwAmAS4QXAJMILgEmEFwCTCC8AJhFeAEwivACYRHgBMInwAmAS4QXAJMILgEm8EqeRhL66pZhXvpSUNOy1qjHWtZgyQzVGmaDmBcAomo0ATCK8AJhEeAEwifACYBLhBcAkwguASYQXAJMILwAmEV4ATCK8AJhEeAEwifACYBJvlWiktwmEzhtFUXCZxczb0NunWbNmrqGFvsmiZcuW9b4uyI2aFwCTCC8AJhFeAEwivACYRHgBMInwAmAS4QXAJMILgEmEFwCTCC8AJhFeAEwivACYRHgBMInwAmASr8QpQosWLRr89TTFvGYmtMz/wrpKKpUKmq+0lNOoMVDzAmAS4QXAJMILgEmEFwCTCC8AJhFeAEwivACYRHgBMInwAmAS4QXAJMILgEmEFwCTCC8AJvE4fCO9VaJ58+YNOp+UlJQ06FsTilnX0HmLeatEaJllZWXBZSIcNS8AJhFeAEwivACYRHgBMInwAmAS4QXAJMILgEmEFwCTCC8AJhFeAEwivACYRHgBMInwAmAS4QXAJF6JU4Tp06cHzzthwoQGf+VLs2bNguYrLy8Pmq+iosKFCn0NT2VlZXCZqVQqaL4ZM2YEl4lw1LwAmER4ATCJ8AJgEuEFwCTCC4BJhBcAkwgvACYRXgBMIrwAmER4ATCJ8AJgEuEFwCTCC4BJqaiY1xQAQCOh5gXAJMILgEmEFwCTCC8AJhFeAEwivACYRHgBMInwAmAS4QXAWfR/fQxdkF9x6NoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_class, prob = predict_user_image(\"1.png\")  # Remplace par le nom de ton fichier image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 12. D√©mo compl√®te : image utilisateur ‚Üí classe CNN ‚Üí image TRM g√©n√©r√©e\n",
    "# =============================================================================\n",
    "\n",
    "def user_demo_with_trm(img_path):\n",
    "    \"\"\"\n",
    "    1) Charge une image utilisateur.\n",
    "    2) La passe dans le CNN pour pr√©dire la classe de v√™tement.\n",
    "    3) G√©n√®re une image 'prototype' avec TRM pour la classe pr√©dite.\n",
    "    4) Affiche les deux c√¥te √† c√¥te.\n",
    "    \"\"\"\n",
    "    # Pr√©traitement identique √† predict_user_image\n",
    "    img = Image.open(img_path).convert(\"L\")\n",
    "    img = img.resize((16, 16))\n",
    "    img_np = np.array(img).astype(np.float32)\n",
    "    img_np_norm = img_np / 127.5 - 1.0\n",
    "\n",
    "    x = img_np_norm[np.newaxis, ..., np.newaxis]  # [1,16,16,1]\n",
    "    preds = cnn.predict(x, verbose=0)\n",
    "    pred_class = int(np.argmax(preds[0]))\n",
    "    prob = float(np.max(preds[0]))\n",
    "\n",
    "    # G√©n√©ration TRM √† partir de la classe pr√©dite\n",
    "    gen_img = trm_small(tf.constant([pred_class])).numpy()[0, :, :, 0]\n",
    "\n",
    "    # Affichage c√¥te √† c√¥te\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    \n",
    "    axes[0].imshow(img_np_norm, cmap=\"gray\", vmin=-1, vmax=1)\n",
    "    axes[0].set_title(f\"Image utilisateur\\nPr√©diction: {pred_class} ‚Äì {class_names[pred_class]}\\n({prob*100:.1f} %)\")\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    axes[1].imshow(gen_img, cmap=\"gray\", vmin=-1, vmax=1)\n",
    "    axes[1].set_title(f\"Prototype TRM\\nClasse {pred_class} ‚Äì {class_names[pred_class]}\")\n",
    "    axes[1].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pred_class, prob\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "# user_demo_with_trm(\"mon_image_vetement.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85083f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.7287481427192688)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_demo_with_trm(\"1.png\")  # Remplace par le nom de ton fichier image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
