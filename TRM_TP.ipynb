{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637d053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ TP TRM-VISION M2 â€“ Fashion-MNIST Kaggle (small vs large + classifier)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/zalando-research/fashionmnist?dataset_version_number=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68.8M/68.8M [00:12<00:00, 5.86MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\User\\.cache\\kagglehub\\datasets\\zalando-research\\fashionmnist\\versions\\4\n",
      "âœ… Fashion-MNIST Kaggle: x_train=(60000, 16, 16), y_train=(60000,)\n",
      "\n",
      "ðŸ”§ EntraÃ®nement TRM small (Fashion-MNIST)...\n",
      "Epoch 1/3\n",
      "32/32 [==============================] - 61s 2s/step - loss: 0.7711 - val_loss: 0.7668\n",
      "Epoch 2/3\n",
      "32/32 [==============================] - 49s 2s/step - loss: 0.7351 - val_loss: 0.7571\n",
      "Epoch 3/3\n",
      "32/32 [==============================] - 49s 2s/step - loss: 0.7291 - val_loss: 0.7499\n",
      "\n",
      "ðŸ”§ EntraÃ®nement TRM large (Fashion-MNIST)...\n",
      "Epoch 1/3\n",
      "32/32 [==============================] - 215s 6s/step - loss: 1.7167 - val_loss: 1.7270\n",
      "Epoch 2/3\n",
      "32/32 [==============================] - 201s 6s/step - loss: 1.7167 - val_loss: 1.7270\n",
      "Epoch 3/3\n",
      "23/32 [====================>.........] - ETA: 54s - loss: 1.7114 "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "\n",
    "print(\"ðŸš€ TP TRM-VISION M2 â€“ Fashion-MNIST Kaggle (small vs large + classifier)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Download Kaggle Fashion-MNIST\n",
    "# =============================================================================\n",
    "path = kagglehub.dataset_download(\"zalando-research/fashionmnist\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Les fichiers du dataset Kaggle contiennent :\n",
    "# - fashion-mnist_train.csv\n",
    "# - fashion-mnist_test.csv\n",
    "train_csv = os.path.join(path, \"fashion-mnist_train.csv\")\n",
    "test_csv  = os.path.join(path, \"fashion-mnist_test.csv\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. TinyBlock\n",
    "# =============================================================================\n",
    "class TinyBlock(layers.Layer):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.ln = layers.LayerNormalization()\n",
    "        self.fc1 = layers.Dense(4 * d, activation=\"gelu\")\n",
    "        self.fc2 = layers.Dense(d)\n",
    "\n",
    "    def call(self, u):\n",
    "        h = self.ln(u)\n",
    "        h = self.fc1(h)\n",
    "        h = self.fc2(h)\n",
    "        return u + h\n",
    "\n",
    "# =============================================================================\n",
    "# 2. TRM-VISION simplifiÃ©\n",
    "# =============================================================================\n",
    "class TRM_VISION(keras.Model):\n",
    "    def __init__(self, img_size=16, d=32, n_rec=2, name_suffix=\"small\"):\n",
    "        super().__init__(name=f\"TRM_VISION_{name_suffix}\")\n",
    "        self.img_size = img_size\n",
    "        self.d = d\n",
    "        self.n_rec = n_rec\n",
    "        \n",
    "        self.cond_emb = layers.Embedding(10, d)  # Fashion-MNIST : 10 classes (t-shirts, shoes, etc.)\n",
    "        self.y0 = self.add_weight(\n",
    "            shape=(1, img_size*img_size, d),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "            name=f\"y0_{name_suffix}\"\n",
    "        )\n",
    "        self.z0 = self.add_weight(\n",
    "            shape=(1, img_size*img_size, d),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "            name=f\"z0_{name_suffix}\"\n",
    "        )\n",
    "        self.block1 = TinyBlock(d)\n",
    "        self.block2 = TinyBlock(d)\n",
    "        self.to_pixels = layers.Dense(1)\n",
    "\n",
    "    def call(self, class_tokens, target_img=None, return_intermediate=False):\n",
    "        B = tf.shape(class_tokens)[0]\n",
    "        L = self.img_size * self.img_size\n",
    "        \n",
    "        # Embedding de la classe et broadcast sur le canvas\n",
    "        c = self.cond_emb(class_tokens)              # [B, d]\n",
    "        c = tf.tile(tf.expand_dims(c, 1), [1, L, 1]) # [B, L, d]\n",
    "        \n",
    "        # Ã‰tats initiaux\n",
    "        y = tf.tile(self.y0, [B, 1, 1])\n",
    "        z = tf.tile(self.z0, [B, 1, 1])\n",
    "        \n",
    "        inter_imgs = []\n",
    "\n",
    "        # n_rec passes internes avec gradient\n",
    "        for _ in range(self.n_rec):\n",
    "            z = self.block2(self.block1(c + y + z))\n",
    "            y = self.block2(self.block1(y + z))\n",
    "\n",
    "        pixels = self.to_pixels(y)\n",
    "        img = tf.tanh(tf.reshape(pixels, [B, self.img_size, self.img_size, 1]))\n",
    "        if return_intermediate:\n",
    "            inter_imgs.append(img)\n",
    "\n",
    "        loss = None\n",
    "        if target_img is not None:\n",
    "            loss = tf.reduce_mean(tf.keras.losses.mse(target_img, img))\n",
    "\n",
    "        if return_intermediate:\n",
    "            return img, loss, inter_imgs\n",
    "        if loss is None:\n",
    "            return img\n",
    "        return img, loss\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Dataset Kaggle Fashion-MNIST â†’ 16x16\n",
    "# =============================================================================\n",
    "\n",
    "def load_fashion_mnist_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    labels = df['label'].values.astype(np.int64)\n",
    "    pixels = df.drop(columns=['label']).values.astype(np.float32)\n",
    "    images = pixels.reshape(-1, 28, 28)\n",
    "    return images, labels\n",
    "\n",
    "x_train_full, y_train = load_fashion_mnist_csv(train_csv)\n",
    "x_test_full,  y_test  = load_fashion_mnist_csv(test_csv)\n",
    "\n",
    "# Normalisation [-1, 1]\n",
    "x_train_full = x_train_full / 127.5 - 1.0\n",
    "x_test_full  = x_test_full  / 127.5 - 1.0\n",
    "\n",
    "# Resize 28x28 â†’ 16x16\n",
    "x_train = np.squeeze(tf.image.resize(tf.expand_dims(x_train_full, -1), [16, 16]).numpy())\n",
    "x_test  = np.squeeze(tf.image.resize(tf.expand_dims(x_test_full,  -1), [16, 16]).numpy())\n",
    "\n",
    "print(f\"âœ… Fashion-MNIST Kaggle: x_train={x_train.shape}, y_train={y_train.shape}\")\n",
    "\n",
    "# Sous-Ã©chantillonnage pour accÃ©lÃ©rer\n",
    "train_idx = 8000\n",
    "val_idx   = 2000\n",
    "\n",
    "x_train_small = x_train[:train_idx]\n",
    "y_train_small = y_train[:train_idx]\n",
    "x_val_small   = x_test[:val_idx]\n",
    "y_val_small   = y_test[:val_idx]\n",
    "\n",
    "# =============================================================================\n",
    "# 4. ModÃ¨les TRM small et large\n",
    "# =============================================================================\n",
    "trm_small = TRM_VISION(img_size=16, d=32, n_rec=2, name_suffix=\"small\")\n",
    "trm_large = TRM_VISION(img_size=16, d=64, n_rec=4, name_suffix=\"large\")\n",
    "\n",
    "trm_small.compile(optimizer='adam', loss='mse')\n",
    "trm_large.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "print(\"\\nðŸ”§ EntraÃ®nement TRM small (Fashion-MNIST)...\")\n",
    "hist_small = trm_small.fit(\n",
    "    y_train_small, x_train_small,\n",
    "    epochs=3, batch_size=256, verbose=1,\n",
    "    validation_data=(y_val_small, x_val_small)\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ”§ EntraÃ®nement TRM large (Fashion-MNIST)...\")\n",
    "hist_large = trm_large.fit(\n",
    "    y_train_small, x_train_small,\n",
    "    epochs=3, batch_size=256, verbose=1,\n",
    "    validation_data=(y_val_small, x_val_small)\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Classifier CNN Fashion-MNIST 16x16\n",
    "# =============================================================================\n",
    "print(\"\\nðŸ”§ EntraÃ®nement CNN classifier Fashion-MNIST (16x16)...\")\n",
    "\n",
    "cnn = keras.Sequential([\n",
    "    layers.Input(shape=(16, 16, 1)),\n",
    "    layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer=\"adam\",\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "\n",
    "cnn.fit(\n",
    "    x_train_small[..., np.newaxis], y_train_small,\n",
    "    epochs=5, batch_size=256, verbose=1,\n",
    "    validation_data=(x_val_small[..., np.newaxis], y_val_small)\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Ã‰valuation: taux de reconnaissance des images gÃ©nÃ©rÃ©es\n",
    "# =============================================================================\n",
    "def eval_trm_with_cnn(trm_model, name, n_samples=500):\n",
    "    labels = np.random.randint(0, 10, size=(n_samples,))\n",
    "    gen_imgs = trm_model(tf.constant(labels)).numpy()  # [N,16,16,1]\n",
    "    preds = cnn.predict(gen_imgs, verbose=0)\n",
    "    pred_labels = preds.argmax(axis=1)\n",
    "    acc = (pred_labels == labels).mean()\n",
    "    print(f\"ðŸ“Š Taux de reconnaissance CNN sur images Fashion-MNIST gÃ©nÃ©rÃ©es ({name}): {acc*100:.2f}%\")\n",
    "    return acc, gen_imgs, labels\n",
    "\n",
    "acc_small, gen_small_imgs, gen_small_labels = eval_trm_with_cnn(trm_small, \"TRM small\")\n",
    "acc_large, gen_large_imgs, gen_large_labels = eval_trm_with_cnn(trm_large, \"TRM large\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Grilles de gÃ©nÃ©ration 0-9 pour les deux modÃ¨les (vÃªtements)\n",
    "# =============================================================================\n",
    "class_names = [\n",
    "    \"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\n",
    "    \"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"\n",
    "]\n",
    "\n",
    "def plot_grid(trm_model, title):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    for i in range(10):\n",
    "        gen_imgs = trm_model(tf.constant([i]))\n",
    "        axes[i//5, i%5].imshow(gen_imgs[0, :, :, 0], cmap='gray', vmin=-1, vmax=1)\n",
    "        axes[i//5, i%5].set_title(f\"{i}: {class_names[i]}\")\n",
    "        axes[i//5, i%5].axis('off')\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_grid(trm_small, \"TRM-VISION SMALL: GÃ©nÃ©ration Fashion-MNIST 0-9\")\n",
    "plot_grid(trm_large, \"TRM-VISION LARGE: GÃ©nÃ©ration Fashion-MNIST 0-9\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. Target vs gÃ©nÃ©rÃ© pour une classe (ex: classe 5 = Sandal)\n",
    "# =============================================================================\n",
    "def plot_target_vs_gen(model, x_test_arr, y_test_arr, digit=5, title_prefix=\"TRM\"):\n",
    "    idx = np.where(y_test_arr == digit)[0][:4]\n",
    "    target = x_test_arr[idx]\n",
    "    gen = model(tf.constant([digit]*4)).numpy()\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    for i in range(4):\n",
    "        axes[0,i].imshow(target[i], cmap='gray', vmin=-1, vmax=1)\n",
    "        axes[0,i].set_title(f\"Vrai {digit}: {class_names[digit]}\")\n",
    "        axes[0,i].axis('off')\n",
    "        axes[1,i].imshow(gen[i, :, :, 0], cmap='gray', vmin=-1, vmax=1)\n",
    "        axes[1,i].set_title(f\"{title_prefix} GÃ©nÃ©rÃ©\")\n",
    "        axes[1,i].axis('off')\n",
    "    plt.suptitle(f\"Classe {digit} ({class_names[digit]}): RÃ©el vs {title_prefix}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_target_vs_gen(trm_small, x_test, y_test, digit=5, title_prefix=\"TRM small\")\n",
    "plot_target_vs_gen(trm_large, x_test, y_test, digit=5, title_prefix=\"TRM large\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. Visualisation trajectoire interne (modÃ¨le large, une classe)\n",
    "# =============================================================================\n",
    "digit_demo = 3  # Dress\n",
    "_, _, inter_imgs = trm_large(tf.constant([digit_demo]), return_intermediate=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(inter_imgs), figsize=(4*len(inter_imgs), 4))\n",
    "if len(inter_imgs) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, img_t in enumerate(inter_imgs):\n",
    "    axes[i].imshow(img_t[0, :, :, 0].numpy(), cmap='gray', vmin=-1, vmax=1)\n",
    "    axes[i].set_title(f\"Step {i+1}\")\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle(f\"Ã‰volution interne TRM large â€“ classe {digit_demo} ({class_names[digit_demo]})\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 10. RÃ©capitulatif console\n",
    "# =============================================================================\n",
    "val_acc_cnn = cnn.evaluate(x_val_small[...,np.newaxis], y_val_small, verbose=0)[1]*100\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ‰ RÃ©sumÃ© TP TRM-VISION â€“ Fashion-MNIST Kaggle\")\n",
    "print(f\"   â†’ TRM small: d=32, n_rec=2, loss fin:  {hist_small.history['loss'][-1]:.4f}\")\n",
    "print(f\"   â†’ TRM large: d=64, n_rec=4, loss fin:  {hist_large.history['loss'][-1]:.4f}\")\n",
    "print(f\"   â†’ CNN val accuracy: {val_acc_cnn:.2f}%\")\n",
    "print(f\"   â†’ Reconnaissance CNN sur images Fashion-MNIST TRM small: {acc_small*100:.2f}%\")\n",
    "print(f\"   â†’ Reconnaissance CNN sur images Fashion-MNIST TRM large: {acc_large*100:.2f}%\")\n",
    "print(\"   â†’ Figures: grilles 0-9 (vÃªtements), vrai vs gÃ©nÃ©rÃ©, trajectoire interne\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
